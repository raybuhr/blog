<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>the ray buhr blog  | Using R as a Production Machine Learning Language (Part I)</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">

    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.55.6" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/docs/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css" rel="stylesheet">
    

    

    
      
    

    

    <meta property="og:title" content="Using R as a Production Machine Learning Language (Part I)" />
<meta property="og:description" content="There’s often confusion amoung the data science and machine learning crowd about the quality of R as a production level language for deploying predictive models. Understandably, many programmers come from languages that don’t behave quite like R does and focus on libraries that R has few of. However, R helps us solve problems of data analysis much more easily that many other languages and some statistical methods have only been implemented in R." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/docs/posts/making-predictions-over-http/" />
<meta property="article:published_time" content="2017-10-17T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2017-10-17T00:00:00&#43;00:00"/>

<meta itemprop="name" content="Using R as a Production Machine Learning Language (Part I)">
<meta itemprop="description" content="There’s often confusion amoung the data science and machine learning crowd about the quality of R as a production level language for deploying predictive models. Understandably, many programmers come from languages that don’t behave quite like R does and focus on libraries that R has few of. However, R helps us solve problems of data analysis much more easily that many other languages and some statistical methods have only been implemented in R.">


<meta itemprop="datePublished" content="2017-10-17T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2017-10-17T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="3871">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Using R as a Production Machine Learning Language (Part I)"/>
<meta name="twitter:description" content="There’s often confusion amoung the data science and machine learning crowd about the quality of R as a production level language for deploying predictive models. Understandably, many programmers come from languages that don’t behave quite like R does and focus on libraries that R has few of. However, R helps us solve problems of data analysis much more easily that many other languages and some statistical methods have only been implemented in R."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-grey">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/docs/" class="f3 fw2 hover-white no-underline white-90 dib">
      the ray buhr blog
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/docs/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/docs/posts/" title="Posts page">
              Posts
            </a>
          </li>
          
        </ul>
      
      



<a href="https://twitter.com/raybuhr" target="_blank" class="link-transition twitter link dib z-999 pt3 pt0-l mr1" title="Twitter link" rel="noopener" aria-label="follow on Twitter——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>




<a href="raybuhr" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="raybuhr" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>





    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">

    <header class="mt4 w-100">
      <p class="f6 b helvetica tracked">
          
        POSTS
      </p>
      <h1 class="f1 athelas mb1">Using R as a Production Machine Learning Language (Part I)</h1>
      
      <time class="f6 mv4 dib tracked" datetime="2017-10-17T00:00:00Z">October 17, 2017</time>
      
      
    </header>

    <section class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l">

<p>There’s often confusion amoung the data science and machine learning
crowd about the quality of R as a production level language for
deploying predictive models. Understandably, many programmers come from
languages that don’t behave quite like R does and focus on libraries
that R has few of. However, R helps us solve problems of data analysis
much more easily that many other languages and some statistical methods
have only been implemented in R. This post has two main goals:</p>

<ol>
<li>helping full-time developers better understand and appreciate what R
is capable of;</li>
<li>helping data scientists use their predictive models in reliable
business settings.</li>
</ol>

<p>Specifically, I want to demonstrate how we can take a trained predictive
model (i.e. statistical learning model or machine learning model) and
deploy it to a server as a RESTful API that accepts JSON requests and
returns JSON responses. To do this, we will use the package
<a href="https://www.rplumber.io/">plumber</a>. By the end of the post we’ll have R
code that allows us access a website through the browser or
programmatically in order to get predictions.</p>

<p><img src="/images/plumber_firefox_screenshot.png" alt="what we’ll have at the end of this blog
post" /></p>

<p><em>Note: The plumber github repo has a giant warning about breaking
changes coming in version 0.4. This is a GOOD thing! When developing an
API like this, you probably want to run it locally in development and
run it locally behind a serious web server like nginx in production.
This post was created using plumber version 0.4.2 so if you follow along
you should not have any problems with the version updates.</em></p>

<h2 id="why-is-this-necessary">Why is this necessary?</h2>

<p>There are many ways predictive models can help an organization such as
forecasting finances to better control budget and spending, recommending
products to customers for increased conversion and/or upselling, or
predicting internet traffic to better prepare infrastructure and reduce
costs. There are also many ways we can architect how we use the model,
each with trade-offs. Often with web applications, getting the model as
close (or preferably inside) of the database will yield best
performance, but unless you have a <a href="https://docs.microsoft.com/en-us/sql/advanced-analytics/tutorials/rtsql-using-r-code-in-transact-sql-quickstart">database that implements R code as
stored
procedures</a>,
that often requires precomputing responses. A RESTful API on the other
hand allows us to remain more flexible by only submitting predictions
upon request, thus enabling the ability to turn predictions on/off or
change models more quickly. Let’s take a more real-world scenario as an
example.</p>

<p><strong>Our objective: recommend a single item for sale to users on their next
login.</strong></p>

<p>If we go with the first deployment method, we would train our model on
the historical data available at the time and upload our predictions to
a database table (let’s call it <code>user_item_recommendations</code>). This
method requires us to work in <em>batch</em> mode. We train our data, submit
our predictions, wait for results to come in, then start all over.
There’s nothing wrong with this approach and it might be right for your
organization, especially if you are very concerned about page load
times. Since the prediction is already calculated and the data sits very
close together (in the same database), the web developers just need to
join the <code>users</code> table to our <code>user_item_recommendations</code> table by the
<code>user_id</code> (<code>uuid</code>, <code>uid</code>, or whatever you use) to quickly identify what
item to display when loading a custom page for each user upon login. A
potential downside is that this process may require modification of the
user login page code, in which case you might have to wait for developer
time to update that part of the codebase. Another potential downside is
that your recommendations might not be very useful unless they change
frequently, which will almost certainly be detrimental to the database
performance and so will have to run at weird hours in the night and
maybe limited to only update a percentage of your users at once.</p>

<p>The API deployment is able to bypass the downsides of the batch update,
database deployment, at the cost of potentially longer page load times.
The good news is that modern javascript has the ability to load content
<em>asynchronously</em> so predictions can come in and load content after most
of the page has already rendered. In this case, we might rethink the
objective and end up not really caring about loading the login web page
with the recommended item, but instead just needing to provide a
prediction when triggered by the login event. That is, when a user
actually completes the login to our website, we could respond in a
number of different manners such as sending a SMS/text message, sending
an email, displaying a pop-up or maybe just banner image in the sidebar.
If you take a peek under the hood in many modern websites, you’ll see
this pattern of call and response often. When loading a page, the
browser sends requests based on the url and cookies you submit,
returning custom content.</p>

<p>The real advantage of using the API method for deploying predictive
models is it allows us to more closely align with the <a href="https://en.wikipedia.org/wiki/Unix_philosophy">Unix
Philosophy</a>. By that, I
mean we can treat each unique predictive model as a separate codebase
that serves <em>one and only one purpose</em> (make a prediction based on
provided data). This philosophy helps better isolate our code which
makes it easier to understand (which can be hard enough as is with
modeling!), easier to maintain, easier to implement versioning, and
easier to montior our results.</p>

<h2 id="getting-started-with-plumber-on-a-trained-model">Getting Started with Plumber on a trained model</h2>

<p>This post assumes you already went through the hard part of data
collection, data cleaning (aka munging, transforming, wrangling, etc.),
model training and model validating. If so, save it as a <code>.Rds</code> – a
binary file native to R that allows us to efficiently transfer models
saved in R over a network.</p>

<p>If you haven’t done this yet, I’m going to quickly breeze though
building one on the <a href="https://www.kaggle.com/c/titanic/data">Titanic example from
Kaggle</a> to predict Survival.
<em>Note that a smaller version is actually built into R, which you can
load with</em> <code>data(Titanic)</code>.</p>

<h3 id="prepping-data">Prepping Data</h3>

<p>Here we start by reading in the data in csv file format to a variable
called <code>titanic_data</code>.</p>

<pre><code>library(readr)
titanic_data &lt;- read_csv(&quot;plumber_titanic/train.csv&quot;)
</code></pre>

<p>In order to ensure the model we build ends up in useful and consistent,
we’ll need the data that gets passed into it to be clean and consistent.
By that I mean things like factors having the same levels and numeric
values that make sense for what they represent. To accomplish that, we
create a simple function to coerce the raw data into the data we expect.
We’ll then be able to apply this function to our training dataset, as
well as any future incoming data we want to predict on.</p>

<pre><code>transform_titantic_data &lt;- function(input_titantic_data) {
  ouput_titantic_data &lt;- data.frame(
    survived = factor(input_titantic_data$Survived, levels = c(0, 1)),
    pclass = factor(input_titantic_data$Pclass, levels = c(1, 2, 3)),
    female = tolower(input_titantic_data$Sex) == &quot;female&quot;,
    age = factor(dplyr::if_else(input_titantic_data$Age &lt; 18, &quot;child&quot;, &quot;adult&quot;, &quot;unknown&quot;), 
                 levels = c(&quot;child&quot;, &quot;adult&quot;, &quot;unknown&quot;))
  )
}

clean_titanic &lt;- transform_titantic_data(titanic_data)
</code></pre>

<h3 id="train-model">Train Model</h3>

<p>When training a machine learning model, it’s important to use validation
techniques otherwise you can’t change it without ruining the assumption
that it will continue to work on new (unseen) data. Here we implement a
very simple technique known as train/test split and train our model on
just the <code>train_df</code> split. For the model, we use a logistic regression
to estimate the probability of survival based on the passenger’s age,
ticket class, and perceived gender. In business settings, logistic
regression is really practical because it is fairly easy to train (no
GPUs needed), very fast at prediction (fast response time for our time),
and the results are much easier to explain and understand. Specifically
the logistic regression coefficients can help us determine the impact of
each independent variable on the odds of the outcome (survival).</p>

<pre><code>set.seed(42)
training_rows &lt;- sample(1:nrow(clean_titanic), size = floor(0.7*nrow(clean_titanic)))
train_df &lt;- clean_titanic[training_rows, ]
test_df &lt;- clean_titanic[-training_rows, ]

titanic_glm &lt;- glm(survived ~ pclass + female + age, 
                   data = clean_titanic, family = binomial(link = &quot;logit&quot;))
</code></pre>

<h3 id="evaluating-model">Evaluating Model</h3>

<p>There are many ways to evaluate model performance, but since that’s not
the point here and there are plenty of areas to confuse and distract
(i.e. I could rant for a while…), let’s keep it simple here. For our
model, we’re using the type <code>response</code> which returns probability as our
prediction. From that, we predict <code>TRUE</code> for survival is our predicted
probability is over 50%. We then compare the predicted survival to the
actual survival in our <code>test_df</code> split to get a <em>confusion matrix</em> and
our predicted accuracy.</p>

<pre><code>test_predictions &lt;- predict(titanic_glm, newdata = test_df, type = &quot;response&quot;) &gt;= 0.5
test_actuals &lt;- test_df$survived == 1
accuracy &lt;- table(test_predictions, test_actuals)
print(accuracy)
print(paste0(&quot;Accuracy: &quot;, round(100 * sum(diag(accuracy))/sum(accuracy), 2), &quot;%&quot;))

                test_actuals
test_predictions FALSE TRUE
           FALSE   147   29
           TRUE     29   63

[1] &quot;Accuracy: 78.36%&quot;
</code></pre>

<p>As you can see, our model does a reasonable job, but could definitely be
dialed in quite a bit. Let’s just call this version 0.0.1 for now, then
as we deploy new and improved versions of our model we can better
justify the investment into our fancy data science.</p>

<h3 id="save-model-to-rds">Save model to RDS</h3>

<p>In order to reuse this model on another computer or just in another R
session, we want to save it. I <em>highly recommend</em> using the built-in,
native to R, efficient binary file format or <code>.Rds</code>. In addition to
being efficient, since it only saves an R object instead of the entire R
session environment like <code>.Rdata</code>, when you load a <code>.Rds</code> file later you
can also save it to a variable, which means we can use the <code>predict</code>
function with it just like normal (like we just did in previous code).</p>

<pre><code>saveRDS(titanic_glm, file = &quot;plumber_titanic/model.Rds&quot;, compress = TRUE)
</code></pre>

<h2 id="building-plumber-api">Building Plumber API</h2>

<p>Finally. The good stuff.</p>

<p>I know it took way too long to get here, but I want to make sure you
understood why this was important and I wanted to make sure people new
to R could follow all the way through.</p>

<h3 id="plumber-api-files">Plumber API files</h3>

<p>We start off by creating two <code>.R</code> files:</p>

<ol>
<li>A file that will define our API endpoints, i.e. the functions we’ll
be exposing.</li>
<li>A file that will read our API definitions and start up a simple web
server with those endpoints available.</li>
</ol>

<p>According to the <code>plumber</code> package documentation, the first file is
conventionally named <code>plumber.R</code>. Feel free to do that if that helps you
remember where you save the plumber code or helps you easily find the
API definitions once you build 30 of these. Otherwise, feel free to name
it whatever you want. I like to name my API code relevant to the model
it exposes, in this case <code>titanic-api.R</code>, since I might include more
than one file in a single directory. That may be bad practice, though so
<em>you do you</em>.</p>

<p>The second file contains your code for routing your API endpoints,
commonly referred to as a <code>router</code>. There are many possible options
available to customive your API here including adding custom
serializers, adding error handlers, encrypting cookies, and even the
ability to serve static sites. For our use case, we have the most bare
bones scenario (keep it simple) so I simply named it <code>server.R</code>. In that
code, we do just 4 things; load in the <code>plumber</code> library, source our API
definitions file, and serve it over port <code>8000</code>.</p>

<pre><code>library(plumber)

serve_model &lt;- plumb(&quot;plumber_titantic/titanic-api.R&quot;)
serve_model$run(port = 8000)
</code></pre>

<p>The other file has the most interesting bits. At the top of the code for
<code>titanic-api.R</code>, we load the <code>plumber</code> library and then read in our
trained model. Then you’ll notice some constants that describe the
current version of the model (and thus the API) and the
variables/features/inputs required. The reason for these constants are
two fold:</p>

<ol>
<li>We want to make iterative progress on our model and thus we want to
know which version is serving predictions once we update it.
Therefore it’s important to update the <code>MODEL_VERSION</code> constant
eveytime you update your model or this file. It’s <em>totally fine</em> to
have millions of versions, but it’s <em>totally not cool</em> to have
multiple versions out there with the same version number.</li>
<li>We want to help developers use our prediction model as a service.
This means having a way to help them understand what is necessary
and what the parameters passed to the API mean. We’ll end up
creating a very simple landing page for our API based on these
variables.</li>
</ol>

<!-- -->

<pre><code>library(plumber)
model &lt;- readRDS(&quot;plumber_titanic/model.Rds&quot;)

MODEL_VERSION &lt;- &quot;0.0.1&quot;
VARIABLES &lt;- list(
  pclass = &quot;Pclass = 1, 2, 3 (Ticket Class: 1st, 2nd, 3rd)&quot;,
  sex = &quot;Sex = male or female&quot;,
  age = &quot;Age = # in years&quot;,
  gap = &quot;&quot;,
  survival = &quot;Successful submission will results in a calculated Survival Probability from 0 to 1 (Unlikely to More Likely)&quot;)
</code></pre>

<h3 id="first-use-of-plumber-annotation-health-check-endpoint">First use of Plumber Annotation - Health check endpoint</h3>

<p>The first function we’ll write will also be the first endpoint we’ll
create. We’re going to start small by simply return a response for any
request containing a status code and our model version. You’ll see that
all we did was write a simple R function, just like we always do.
However, by simply adding a special type of comment right above our
function, <code>plumber</code> will automagically be able to turn our code into an
HTTP API. The details of this are maybe a little <em>complex</em>, but not
<em>complicated</em>. I encourage you to read up on decorator functions if you
are curious, but I’m going to pass on explaining it for now other than
saying they work by telling the program that your function should get
passed into another function as described in the annotation (special
comment).</p>

<p>In this function, the decorator we applied is <code>@get /healthcheck</code> which
tells plumber to expose this function to HTTP GET requests at the url
<a href="http://127.0.0.1:8000/healthcheck" class="uri"><a href="http://127.0.0.1:8000/healthcheck">http://127.0.0.1:8000/healthcheck</a></a>.</p>

<pre><code>#* @get /healthcheck
health_check &lt;- function() {
  result &lt;- data.frame(
    &quot;input&quot; = &quot;&quot;,
    &quot;status&quot; = 200,
    &quot;model_version&quot; = MODEL_VERSION
  )

  return(result)
}
</code></pre>

<p>For the function above, think of it as a way to test whether the API is
actually working. In fact, if you stop right here and save your two
files, then source the <code>server.R</code> file it should start a web server at
your localhost over port 8000 that you could go check in the browser and
see if it’s running at
<a href="http://127.0.0.1:8000/healthcheck" class="uri"><a href="http://127.0.0.1:8000/healthcheck">http://127.0.0.1:8000/healthcheck</a></a>.
Over time, I think you’ll find having a simple endpoint like this can be
really helpful for debugging whether your model is having problems or if
the API server is having problems.</p>

<p><img src="/images/plumber_healthcheck_screenshot.png" alt="health check page" /></p>

<h3 id="landing-page">Landing Page</h3>

<p>This is probably unnecessary as all software developers are super smart
and obviously know exactly what data to pass a simple REST API, but just
in case let’s make a simple home page for users accessing our API to
help get them acquainted. You’ll notice here in addition to the <code>@get</code>
decorator, we also introduce a second decorator, <code>@html</code> that tells
plumber to render responses to this endpoint as <code>html</code> content instead
of <code>json</code>.</p>

<pre><code>#* @get /
#* @html
home &lt;- function() {
  title &lt;- &quot;Titanic Survival API&quot;
  body_intro &lt;-  &quot;Welcome to the Titanic Survival API!&quot;
  body_model &lt;- paste(&quot;We are currently serving model version:&quot;, MODEL_VERSION)
  body_msg &lt;- paste(&quot;To received a prediction on survival probability,&quot;, 
                     &quot;submit the following variables to the &lt;b&gt;/survival&lt;/b&gt; endpoint:&quot;,
                     sep = &quot;\n&quot;)
  body_reqs &lt;- paste(VARIABLES, collapse = &quot;&lt;br&gt;&quot;)

  result &lt;- paste(
    &quot;&lt;html&gt;&quot;,
    &quot;&lt;h1&gt;&quot;, title, &quot;&lt;/h1&gt;&quot;, &quot;&lt;br&gt;&quot;,
    &quot;&lt;body&gt;&quot;, 
    &quot;&lt;p&gt;&quot;, body_intro, &quot;&lt;/p&gt;&quot;,
    &quot;&lt;p&gt;&quot;, body_model, &quot;&lt;/p&gt;&quot;,
    &quot;&lt;p&gt;&quot;, body_msg, &quot;&lt;/p&gt;&quot;,
    &quot;&lt;p&gt;&quot;, body_reqs, &quot;&lt;/p&gt;&quot;,
    &quot;&lt;/body&gt;&quot;,
    &quot;&lt;/html&gt;&quot;,
    collapse = &quot;\n&quot;
  )

  return(result)
}
</code></pre>

<p>The html we generate with this function is pretty basic, but if you are
unfamiliar we are displaying:</p>

<ul>
<li>a page header with the name of the API</li>
<li>a short welcome message</li>
<li>a sentence stating the current version of the model being served</li>
<li>a short explanation of how to use the API and what the response
means</li>
</ul>

<p>Sourcing the <code>server.R</code> file now should allow you to check it out and
see:</p>

<p><img src="/images/plumber_landing_page_screenshot.png" alt="api landing page" /></p>

<h3 id="prediction-endpoint">Prediction Endpoint</h3>

<p>Before jumping straight into the function to make predictions, let’s
start by implementing the helper function we used to clead the data
before training the model, as well as a helper function to validate that
inputs passed to our API are useful and appropriate.</p>

<pre><code>transform_titantic_data &lt;- function(input_titantic_data) {
  ouput_titantic_data &lt;- data.frame(
    pclass = factor(input_titantic_data$Pclass, levels = c(1, 2, 3)),
    female = tolower(input_titantic_data$Sex) == &quot;female&quot;,
    age = factor(dplyr::if_else(input_titantic_data$Age &lt; 18, &quot;child&quot;, &quot;adult&quot;, &quot;unknown&quot;), 
                 levels = c(&quot;child&quot;, &quot;adult&quot;, &quot;unknown&quot;))
  )
}

validate_feature_inputs &lt;- function(age, pclass, sex) {
  age_valid &lt;- (age &gt;= 0 &amp; age &lt; 200 | is.na(age))
  pclass_valid &lt;- (pclass %in% c(1, 2, 3))
  sex_valid &lt;- (sex %in% c(&quot;male&quot;, &quot;female&quot;))
  tests &lt;- c(&quot;Age must be between 0 and 200 or NA&quot;, 
             &quot;Pclass must be 1, 2, or 3&quot;, 
             &quot;Sex must be either male or female&quot;)
  test_results &lt;- c(age_valid, pclass_valid, sex_valid)
  if(!all(test_results)) {
    failed &lt;- which(!test_results)
    return(tests[failed])
  } else {
    return(&quot;OK&quot;)
  }
}
</code></pre>

<p>You may notice that the <code>transform_titantic_data</code> function is almost
identical, but not quite. Since we are now just making predictions, we
don’t need to format the output variable we trained against since it
won’t be in the request. For the second function, you should notice it
is a series of logical tests against each feature separately, that we
then parse to identify if there are any exceptions we might need to
notify in the response. For example, if the Age submitted is excessive
or negative, we probably want to tell the developer to check their code
instead of just returning a probability.</p>

<p>Now onto the main event.</p>

<p>You can see that we implement the API to the same endpoint of
<code>/survival</code> and we allow both GET and POST requests to that same
endpoint. Technically this shouldn’t make a lot of sense as HTTP
requests should roughly map to the database operations in the following
fashion according to <a href="https://codeplanet.io/principles-good-restful-api-design/">principles of good API
design</a>:</p>

<pre><code>GET (SELECT): Retrieve a specific Resource from the Server, or a listing of Resources.
POST (CREATE): Create a new Resource on the Server.
PUT (UPDATE): Update a Resource on the Server, providing the entire Resource.
PATCH (UPDATE): Update a Resource on the Server, providing only changed attributes.
DELETE (DELETE): Remove a Resource from the Server.
</code></pre>

<p>However, while we really only want to allow users to GET a single
prediction back, but not all servers are ok with this strategy. In
theory, a GET request should be to retrieve a specific thing (which this
is), but allowing different payloads in the GET request can break any
caching the server might provide. So even though we want to accept a GET
request with a payload or pass in the payload as URL query string, we’re
going to do both to make everyone unhappy.</p>

<pre><code>#* @post /survival
#* @get /survival
predict_survival &lt;- function(Age=NA, Pclass=NULL, Sex=NULL) {
  age = as.integer(Age)
  pclass = as.integer(Pclass)
  sex = tolower(Sex)
  valid_input &lt;- validate_feature_inputs(age, pclass, sex)
  if (valid_input[1] == &quot;OK&quot;) {
    payload &lt;- data.frame(Age=age, Pclass=pclass, Sex=sex)
    clean_data &lt;- transform_titantic_data(payload)
    prediction &lt;- predict(model, clean_data, type = &quot;response&quot;)
    result &lt;- list(
      input = list(payload),
      reposnse = list(&quot;survival_probability&quot; = prediction,
                      &quot;survival_prediction&quot; = (prediction &gt;= 0.5)
                      ),
      status = 200,
      model_version = MODEL_VERSION)
  } else {
    result &lt;- list(
      input = list(Age = Age, Pclass = Pclass, Sex = Sex),
      response = list(input_error = valid_input),
      status = 400,
      model_version = MODEL_VERSION)
  }

  return(result)
}
</code></pre>

<p>Compared to the rest of the code above, this function is definitely
doing a lot more. First off, we specifically cast our input variables to
the data types we want. JSON, which is how the request comes in, is not
strongly typed and so we may receive an Age of “22” which would work
fine, but fail if we didn’t convert to an integer in R. Next, we use the
helper function to test and validate the inputs passed in the request
and save the results to a variable named <code>valid_input</code>. Then we proceed
down two separate paths.</p>

<p>If the <code>valid_input</code> was <code>OK</code>, then we join the data passed in the
request into a <code>data.frame</code>, clean that <code>data.frame</code>, and then run the
<code>predict</code> function on the request data using our trained model. Instead
of just returning the prediction directly, we want to return it in a
more standard JSON format with some additional information helpful to us
later. Specifically, we return JSON containing:</p>

<ul>
<li>the input passed to the predict function</li>
<li>the prediction as both a probability (0.0 to 1.0) and a
recommendation (TRUE/FALSE)</li>
<li>a status code of <code>200</code> since everything worked <code>OK</code></li>
<li>the version of the model the prediction came from</li>
</ul>

<p><img src="/images/plumber_survival_prediction_screenshot.png" alt="predict success" /></p>

<p>Why do we need all that? Well, in addition to making predictions, as
data scientists we want to collect data. We want to log how often the
model is being used. We want to later compare how strongly our
recommendation correlates with other actions. We want to be able to
debug our prediction API if things start to go awry.</p>

<p>If the <code>valid_input</code> was not <code>OK</code>, we don’t want the API to just break
down. Instead we want it to return useful information, like why it
didn’t work. Therefore when we can’t validate the request data, we
return:</p>

<ul>
<li>the exact input passed to the API (not necessarily the same as what
would have been passed to the model if had been ok)</li>
<li>an array of the errors with the input to give the developer a better
understanding of why the request failed</li>
<li>a status code of <code>400</code> which indicates a <code>Bad Request</code></li>
<li>the version of the model that made the response</li>
</ul>

<p><img src="/images/plumber_survival_error_screenshot.png" alt="predict error" /></p>

<p>In addition to being able to use the API from a web browser, you can
also use other tools, like curl through the command line.</p>

<p><img src="/images/plumber_curl_screenshot.png" alt="curl api" /></p>

<h3 id="putting-it-all-together">Putting it all together</h3>

<p>Once you’ve got your code ready, let’s go through this checklist to make
sure everything is in order:</p>

<ol>
<li>We have our code to build a model isolated from the code to deploy
the model.</li>
<li>We have our model trained and saved to a file.</li>
<li>We have our code to deploy the model as a RESTful API in two files,
one defining our API in decorated functions and one to serve that
first file.</li>
<li>We have versioning for our deployment and make sure to update it
with each change.</li>
<li>We have error handing in place to ensure bad requests get returned
with useful information.</li>
</ol>

<h2 id="concluding-remarks">Concluding Remarks</h2>

<p>Full source code to build this plumber based API is available at
<a href="https://github.com/raybuhr/plumber-titanic">https://github.com/raybuhr/plumber-titanic</a>.</p>

<p>Read through the <a href="https://www.rplumber.io/docs/">Plumber Documentation</a>.
By default, all plumber endpoints return responses as <code>application/json</code>
using the <code>jsonlite::toJSON</code> function. You can read more about
alternative serializers (i.e. other types of response content) <a href="https://www.rplumber.io/docs/rendering-and-output.html#serializers">here in
the plumber
docs</a>.
In my experience, you may be fine with the default serializers or you
may need to get pretty deep in the weeds depending on how you need to
receive and return results.</p>

<p>Deploy your models somewhere that is easy to find and easy to download
for your servers, such as AWS S3 or Google Cloud Storage. GitHub is
usually not a very good place to store models, unless they are very
small and they benefit from reviewing the text differences (which <code>.Rds</code>
does not).</p>

<p>In Part II of this post, we’ll explore:</p>

<ul>
<li>uploading our code to a version control system like GitHub</li>
<li>uploading our <code>.Rds</code> file to cloud storage</li>
<li>spinning up a virtual machine in the cloud to host our API</li>
<li>using Docker to <em>“containerize”</em> our API allowing us to run multiple
instances at once</li>
<li>using Nginx to serve up those docker instances of this API and act
as a load balancer</li>
</ul>
<ul class="pa0">
  
</ul>
<div class="mt6">
      
      
      </div>
    </section>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-grey bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="/docs/" >
    &copy; 2019 the ray buhr blog
  </a>
    <div>



<a href="https://twitter.com/raybuhr" target="_blank" class="link-transition twitter link dib z-999 pt3 pt0-l mr1" title="Twitter link" rel="noopener" aria-label="follow on Twitter——Opens in a new window">
  <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>




<a href="raybuhr" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="raybuhr" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>




</div>
  </div>
</footer>

    

  <script src="/docs/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
